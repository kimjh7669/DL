{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c61dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "out_ch = 10\n",
    "in_ch = 100\n",
    "\n",
    "class double_conv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None, input_shape = [28,28, in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class inconv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class down(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = keras.Sequential(\n",
    "            layers.MaxPooling2D(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class up(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            self.up = layers.UpSampling2D(size = (2,2), interpolation='bilinear')\n",
    "        else:\n",
    "            self.up = layers.Conv2DTranspose(in_ch//2, 2, stride=(2, 2))\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x1.size()[2] - x2.size()[2]\n",
    "        diffY = x1.size()[3] - x2.size()[3]\n",
    "        x2 = F.pad(x2, (diffX // 2, int(diffX / 2),\n",
    "                        diffY // 2, int(diffY / 2)))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "model = up(in_ch, out_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1614918e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_28 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 100)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6edd672394b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdouble_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_ch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_ch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m# model.forward(model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# print(model.summary())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-6edd672394b5>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_ch, out_ch)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_ch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_ch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         self.conv = keras.Sequential([\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_ch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0min_ch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# keras에서 input_channel의 수가 중요한가?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                                 input_list)\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    860\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2682\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2683\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2684\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2685\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    235\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_28 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 100)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "out_ch = 10\n",
    "in_ch = 100\n",
    "# model = keras.Sequential([\n",
    "#     layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None, input_shape=(28,28,in_ch)), # keras에서 input_channel의 수가 중요한가?\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu'),\n",
    "#     layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')   \n",
    "# ])\n",
    "\n",
    "class double_conv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None, input_shape = [in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "model = double_conv(in_ch, out_ch)\n",
    "# model.forward(model)\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e99b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"echo\", help=\"write the string u want to echo\")\n",
    "args = parser.parse_args()\n",
    "print(args.echo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = torch.arange(10).reshape(5,2)\n",
    "# print(x)\n",
    "print(torch.split(x, 2),1)\n",
    "# print(torch.split(x, [1,4]))\n",
    "\n",
    "y = np.arange(10).reshape(5,2)\n",
    "try:\n",
    "    print(tf.split(y, 2),1)\n",
    "except:\n",
    "    print(\"Hello\")\n",
    "# print(tf.split(y, [1,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "print(nn.ModuleList(nn.Linear(10,10) for i in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cea798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "out_ch = 10\n",
    "in_ch = 3\n",
    "\n",
    "model = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None, input_shape = [28,28, in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "\n",
    "# model.summary()\n",
    "cell_list = []\n",
    "for i in range(10):\n",
    "    cell_list.append(model)\n",
    "for i in range(10):\n",
    "    print(cell_list[i].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =  nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "cell_list1 = []\n",
    "for i in range(10):\n",
    "    cell_list1.append(model1)\n",
    "ModuleList1 = nn.ModuleList(cell_list1)\n",
    "print(ModuleList1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None, input_shape = [28,28, in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "model2 = double_conv(in_ch, out_ch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv1(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv1, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "model3 = double_conv1(in_ch, out_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.random.randn(28*28*3).reshape(1,28, 28, 3)\n",
    "\n",
    "print(model2.conv(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0fc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST('data/', train = True, transform = transformation, download = True)\n",
    "test_dataset = datasets.MNIST('data/', train = False, transform = transformation, download = True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = next(iter(train_loader))\n",
    "def plot_img(image):\n",
    "    image = image.numpy()[0]\n",
    "    mean = 0.1307\n",
    "    std = 0.3081\n",
    "    image = ((std * image) + mean) \n",
    "    plt.imshow(image, cmap = 'gray') \n",
    "    plt.show()\n",
    "plot_img(sample_data[0][2])\n",
    "plot_img(sample_data[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26243403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d(p = 0.1)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1) \n",
    "model = Net()\n",
    "# if is_cuda:\n",
    "#     model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "data, target = next(iter(train_loader))\n",
    "output = model(Variable(data.cuda()))\n",
    "print('output:', output.size(), \"\\ntarget:\", target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "x = tf.reshape(tf.range(12), (3,4))\n",
    "print(x)\n",
    "p, q, r = tf.unstack(x)\n",
    "p.shape.as_list()\n",
    "print(p,q,r)\n",
    "\n",
    "y = torch.reshape(torch.tensor(range(12)), (3,4))\n",
    "\n",
    "a,b,c = torch.unbind(y)\n",
    "print(a,b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4009c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import operator\n",
    "\n",
    "vgg16_bn = models.vgg16_bn(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999295ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_vgg16 = tf.keras.applications.VGG16(\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vgg16_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3088f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_vgg16.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(9)\n",
    "x = x.reshape(1,1,3,3)\n",
    "y = tf_vgg16(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ad388",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "x.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.squeeze(x)\n",
    "y.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.squeeze(x, 0)\n",
    "y.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.squeeze(x, 1)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "test_image_dir = \"C:/Users/Lim-LAB/Desktop/Git/Robust-Lane-Detection/Tensorflow/LaneDetectionCode/data/testset/image/1_1.jpg\"\n",
    "test_label_dir = \"C:/Users/Lim-LAB/Desktop/Git/Robust-Lane-Detection/Tensorflow/LaneDetectionCode/data/testset/truth/1_13.jpg\"\n",
    "data = Image.open(test_image_dir)\n",
    "label = Image.open(test_label_dir)\n",
    "\n",
    "ndata = np.array(data)\n",
    "plt.imshow(ndata)\n",
    "plt.show()\n",
    "ndata = ndata[np.newaxis, ...]\n",
    "nlabel = np.array(label)\n",
    "plt.imshow(nlabel)\n",
    "nlabel = nlabel[np.newaxis, ... , np.newaxis]\n",
    "ndata = ndata/255.\n",
    "# print(ndata)\n",
    "nlabel = nlabel/255.\n",
    "print(nlabel.shape)\n",
    "plt.show()\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((ndata, nlabel))\n",
    "print(type(test_ds))\n",
    "\n",
    "for img, label in test_ds.take(1):\n",
    "    # print(img.shape, label.shape)\n",
    "    model(img, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import config\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from utils_tensorflow import *\n",
    "import operator\n",
    "from config import args_setting\n",
    "import numpy as np\n",
    "\n",
    "def unpool(value, name='unpool'):\n",
    "    \"\"\"N-dimensional version of the unpooling operation from\n",
    "    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
    "\n",
    "    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\n",
    "    :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n",
    "    \"\"\"\n",
    "    # print(tf.name_scope)\n",
    "    with tf.name_scope(name) as scope:\n",
    "        sh = value.get_shape().as_list()\n",
    "        print(sh)\n",
    "        dim = len(sh[1:-1])\n",
    "        print(dim)\n",
    "        out = (tf.reshape(value, [-1] + sh[-dim:]))\n",
    "        # print(out)\n",
    "        for i in range(dim, 0, -1):\n",
    "            # print(i)\n",
    "            out = tf.concat([out, tf.zeros_like(out)], i)\n",
    "        print(out)\n",
    "        out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\n",
    "        print(out_size)\n",
    "        out = tf.reshape(out, out_size, name=scope)\n",
    "    return out\n",
    "\n",
    "def generate_model(args):\n",
    "\n",
    "    use_cuda = args.cuda and tf.test.is_gpu_available()\n",
    "    device = tf.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    assert args.model in [ 'UNet-ConvLSTM', 'SegNet-ConvLSTM', 'UNet', 'SegNet']\n",
    "    if args.model == 'SegNet-ConvLSTM':\n",
    "        model = SegNet_ConvLSTM().to(device)\n",
    "    elif args.model == 'SegNet':\n",
    "        model = SegNet().to(device)\n",
    "    elif args.model == 'UNet-ConvLSTM':\n",
    "        model =UNet_ConvLSTM(config.img_channel, config.class_num).to(device)\n",
    "    elif args.model == 'UNet':\n",
    "        model = UNet(config.img_channel, config.class_num).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "class UNet_ConvLSTM(tf.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet_ConvLSTM, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up(1024, 256)\n",
    "        self.up2 = up(512, 128)\n",
    "        self.up3 = up(256, 64)\n",
    "        self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "        self.convlstm = ConvLSTM(input_size=(8,16),\n",
    "                                 input_dim=512,\n",
    "                                 hidden_dim=[512, 512],\n",
    "                                 kernel_size=(3,3),\n",
    "                                 num_layers=2,\n",
    "                                 batch_first=False,\n",
    "                                 bias=True,\n",
    "                                 return_all_layers=False)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.unstack(x, axis=1)\n",
    "        data = []\n",
    "        for item in x:\n",
    "            x1 = self.inc(item)\n",
    "            x2 = self.down1(x1)\n",
    "            x3 = self.down2(x2)\n",
    "            x4 = self.down3(x3)\n",
    "            x5 = self.down4(x4)\n",
    "            data.append(tf.expand_dims(x5, axis = 0))\n",
    "        data = layers.concatenate(data, axis=0)\n",
    "        lstm, _ = self.convlstm(data)\n",
    "        test = lstm[0][ -1,:, :, :, :]\n",
    "        x = self.up1(test, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x, test\n",
    "\n",
    "\n",
    "\n",
    "class UNet(tf.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up(1024, 256)\n",
    "        self.up2 = up(512, 128)\n",
    "        self.up3 = up(256, 64)\n",
    "        self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SegNet_ConvLSTM(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(SegNet_ConvLSTM,self).__init__()\n",
    "        self.vgg16_bn = tf.keras.applications.VGG16(include_top=False)\n",
    "        self.relu = layers.ReLU(),\n",
    "        self.index_MaxPool = layers.MaxPooling2D(pool_size=(2,2), strides=2, data_format = 'channels_last')\n",
    "        self.index_UnPool = unpool(kernel_size=2, stride=2)\n",
    "        # net struct\n",
    "        self.conv1_block = keras.Sequential([self.vgg16_bn.layers[0],  # input layer\n",
    "                                        self.vgg16_bn.layers[1],  # conv2d(3,64,(3,3))\n",
    "                                        self.vgg16_bn.layers[2]  # conv2d(3,64,(3,3))\n",
    "                                        ])\n",
    "        self.conv2_block = keras.Sequential([self.vgg16_bn.layers[4],\n",
    "                                        self.vgg16_bn.layers[5]\n",
    "                                        ])\n",
    "        self.conv3_block = keras.Sequential([self.vgg16_bn.layers[7],\n",
    "                                        self.vgg16_bn.layers[8],\n",
    "                                        self.vgg16_bn.layers[9]\n",
    "                                        ])\n",
    "        self.conv4_block = keras.Sequential([self.vgg16_bn.layers[11],\n",
    "                                        self.vgg16_bn.layers[12],\n",
    "                                        self.vgg16_bn.layers[13]\n",
    "                                        ])\n",
    "        self.conv5_block = keras.Sequential([self.vgg16_bn.layers[15],\n",
    "                                        self.vgg16_bn.layers[16],\n",
    "                                        self.vgg16_bn.layers[17]\n",
    "                                        ])\n",
    "\n",
    "        self.upconv5_block = keras.Sequential(\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv4_block = keras.Sequential(\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv3_block = keras.Sequential(\n",
    "                                        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(128, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv2_block = keras.Sequential(\n",
    "                                        layers.Conv2D(128, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv1_block = keras.Sequential(\n",
    "                                        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(config.class_num, (3, 3), padding='same'),\n",
    "                                        )\n",
    "        self.convlstm = ConvLSTM(input_size=(4,8),\n",
    "                                 input_dim=512,\n",
    "                                 hidden_dim=[512, 512],\n",
    "                                 kernel_size=(3,3),\n",
    "                                 num_layers=2,\n",
    "                                 batch_first=False,\n",
    "                                 bias=True,\n",
    "                                 return_all_layers=False)\n",
    "    def __call__(self, x):\n",
    "        x = tf.unstack(x, axis=1)\n",
    "        data = []\n",
    "        for item in x:\n",
    "            f1, idx1 = self.index_MaxPool(self.conv1_block(item))\n",
    "            f2, idx2 = self.index_MaxPool(self.conv2_block(f1))\n",
    "            f3, idx3 = self.index_MaxPool(self.conv3_block(f2))\n",
    "            f4, idx4 = self.index_MaxPool(self.conv4_block(f3))\n",
    "            f5, idx5 = self.index_MaxPool(self.conv5_block(f4))\n",
    "            data.append(tf.expand_dims(f5, axis = 0))\n",
    "        data = layers.concatenate(data, axis=0)\n",
    "        lstm, _ = self.convlstm(data)\n",
    "        test = lstm[0][-1,:,:,:,:]\n",
    "        up6 = self.index_UnPool(test,idx5)\n",
    "        up5 = self.index_UnPool(self.upconv5_block(up6), idx4)\n",
    "        up4 = self.index_UnPool(self.upconv4_block(up5), idx3)\n",
    "        up3 = self.index_UnPool(self.upconv3_block(up4), idx2)\n",
    "        up2 = self.index_UnPool(self.upconv2_block(up3), idx1)\n",
    "        up1 = self.upconv1_block(up2)\n",
    "        return tf.nn.log_softmax(up1, axis=1)\n",
    "\n",
    "\n",
    "class SegNet(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(SegNet,self).__init__()\n",
    "        self.vgg16_bn = tf.keras.applications.VGG16(include_top=False)\n",
    "        self.relu = layers.ReLU(),\n",
    "        self.index_MaxPool = layers.MaxPooling2D(pool_size=(2,2), strides=2, data_format = 'channels_last')\n",
    "        self.index_UnPool = unpool(kernel_size=2, stride=2)\n",
    "        # net struct\n",
    "\n",
    "        self.conv1_block = keras.Sequential([self.vgg16_bn.layers[0],  # input layer\n",
    "                                        self.vgg16_bn.layers[1],  # conv2d(3,64,(3,3))\n",
    "                                        self.vgg16_bn.layers[2]  # conv2d(3,64,(3,3))\n",
    "                                        ])\n",
    "        self.conv2_block = keras.Sequential([self.vgg16_bn.layers[4],\n",
    "                                        self.vgg16_bn.layers[5]\n",
    "                                        ])\n",
    "        self.conv3_block = keras.Sequential([self.vgg16_bn.layers[7],\n",
    "                                        self.vgg16_bn.layers[8],\n",
    "                                        self.vgg16_bn.layers[9]\n",
    "                                        ])\n",
    "        self.conv4_block = keras.Sequential([self.vgg16_bn.layers[11],\n",
    "                                        self.vgg16_bn.layers[12],\n",
    "                                        self.vgg16_bn.layers[13]\n",
    "                                        ])\n",
    "        self.conv5_block = keras.Sequential([self.vgg16_bn.layers[15],\n",
    "                                        self.vgg16_bn.layers[16],\n",
    "                                        self.vgg16_bn.layers[17]\n",
    "                                        ])\n",
    "\n",
    "        self.upconv5_block = keras.Sequential(\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv4_block = keras.Sequential(\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv3_block = keras.Sequential(\n",
    "                                        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(128, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv2_block = keras.Sequential(\n",
    "                                        layers.Conv2D(128, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu\n",
    "                                        )\n",
    "        self.upconv1_block = keras.Sequential(\n",
    "                                        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "                                        layers.BatchNormalization(epsilon=1e-05, momentum=0.9),\n",
    "                                        self.relu,\n",
    "                                        layers.Conv2D(config.class_num, (3, 3), padding='same'),\n",
    "                                        )\n",
    "    def __call__(self, x):\n",
    "        f1, idx1 = self.index_MaxPool(self.conv1_block(x))\n",
    "        f2, idx2 = self.index_MaxPool(self.conv2_block(f1))\n",
    "        f3, idx3 = self.index_MaxPool(self.conv3_block(f2))\n",
    "        f4, idx4 = self.index_MaxPool(self.conv4_block(f3))\n",
    "        f5, idx5 = self.index_MaxPool(self.conv5_block(f4))\n",
    "        up6 = self.index_UnPool(f5,idx5)\n",
    "        up5 = self.index_UnPool(self.upconv5_block(up6), idx4)\n",
    "        up4 = self.index_UnPool(self.upconv4_block(up5), idx3)\n",
    "        up3 = self.index_UnPool(self.upconv3_block(up4), idx2)\n",
    "        up2 = self.index_UnPool(self.upconv2_block(up3), idx1)\n",
    "        up1 = self.upconv1_block(up2)\n",
    "\n",
    "        return tf.nn.log_softmax(up1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = up(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 128, 256, 3)\n(1, 128, 256, 1)\n(1, 256, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "y = model1(ndata, nlabel)\n",
    "print(ndata.shape)\n",
    "print(nlabel.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = UNet(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model2(ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 128, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ConvLSTM((128, 256), 3, 3, (3, 3), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5, 64, 128, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "ndata1 = layers.concatenate([ndata, ndata], axis = 0)\n",
    "for i in range(5):\n",
    "    ndata1 = layers.concatenate([ndata1, ndata1], axis = 0)\n",
    "ndata2 = ndata1.numpy()\n",
    "for i in range(5):\n",
    "    data.append(ndata2)\n",
    "# print(data)\n",
    "data = tf.constant(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,130,258,12] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-de31bc975f48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Lim-LAB\\Desktop\\Git\\Robust-Lane-Detection\\Tensorflow\\utils_tensorflow.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mcur_layer_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lim-LAB\\Desktop\\Git\\Robust-Lane-Detection\\Tensorflow\\utils_tensorflow.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_cur\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# concatenate along channel axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mcombined_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mfor_split_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m--> 424\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m     name=None):\n\u001b[1;32m-> 1013\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1144\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2595\u001b[0m     \u001b[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2596\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2597\u001b[1;33m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   2598\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2599\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,130,258,12] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "lstm, _ = model3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.zeros([1,3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# import numpy as np\n",
    "\n",
    "# class double_conv(tf.Module): \n",
    "#     def __init__(self, in_ch, out_ch):\n",
    "#         super(double_conv, self).__init__()\n",
    "#         self.conv = keras.Sequential([\n",
    "#             layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), \n",
    "#             layers.BatchNormalization(momentum=0.9),\n",
    "#             layers.Activation('relu'),\n",
    "#             layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), \n",
    "#             layers.BatchNormalization(momentum=0.9),\n",
    "#             layers.Activation('relu')            \n",
    "#         ])\n",
    "#     def __call__(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         return x\n",
    "\n",
    "# class inconv(tf.Module):\n",
    "#     def __init__(self, in_ch, out_ch):\n",
    "#         super(inconv, self).__init__()\n",
    "#         self.conv = double_conv(in_ch, out_ch)\n",
    "#     def __call__(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         return x\n",
    "\n",
    "# class down(tf.Module):\n",
    "#     def __init__(self, in_ch, out_ch):\n",
    "#         super(down, self).__init__()\n",
    "#         self.mpconv = keras.Sequential([\n",
    "#             layers.MaxPooling2D(2),\n",
    "#             layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), \n",
    "#             layers.BatchNormalization(momentum=0.9),\n",
    "#             layers.Activation('relu'),\n",
    "#             layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), \n",
    "#             layers.BatchNormalization(momentum=0.9),\n",
    "#             layers.Activation('relu') \n",
    "#         ])\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         x = self.mpconv(x)\n",
    "#         return x\n",
    "        \n",
    "\n",
    "# class up(tf.Module):\n",
    "#     def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "#         super(up, self).__init__()\n",
    "\n",
    "#         #  would be a nice idea if the upsampling could be learned too,\n",
    "#         #  but my machine do not have enough memory to handle all those weights\n",
    "#         if bilinear:\n",
    "#             self.up = layers.UpSampling2D(size = (2,2), interpolation='bilinear')\n",
    "#         else:\n",
    "#             self.up = layers.Conv2DTranspose(in_ch//2, 2, stride=(2, 2))\n",
    "\n",
    "#         self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "#     def __call__(self, x1, x2):\n",
    "#         x1 = self.up(x1) \n",
    "#         diffX = x1.shape[1] - x2.shape[1] # height ?\n",
    "#         diffY = x1.shape[2] - x2.shape[2] # width ?\n",
    "#         padding = [[0,0], [(diffX)// 2, int((diffX + 1)/ 2)], [diffY // 2, int((diffY+1) / 2)], [0,0]]\n",
    "#         x2 = tf.pad(x2, padding)\n",
    "#         x = layers.concatenate([x2, x1], axis=3)\n",
    "#         x = self.conv(x)\n",
    "#         return x\n",
    "\n",
    "# class outconv(tf.Module):\n",
    "#     def __init__(self, in_ch, out_ch):\n",
    "#         super(outconv, self).__init__()\n",
    "#         self.conv = layers.Conv2D(out_ch, (1, 1), padding = \"SAME\", activation=None)\n",
    "#     def __call__(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class ConvLSTMCell(tf.Module):\n",
    "\n",
    "#     def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
    "#         \"\"\"\n",
    "#         Initialize ConvLSTM cell.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         input_size: (int, int)\n",
    "#             Height and width of input tensor as (height, width).\n",
    "#         input_dim: int\n",
    "#             Number of channels of input tensor.\n",
    "#         hidden_dim: int\n",
    "#             Number of channels of hidden state.\n",
    "#         kernel_size: (int, int)\n",
    "#             Size of the convolutional kernel.\n",
    "#         bias: bool\n",
    "#             Whether or not to add the bias.\n",
    "#         \"\"\"\n",
    "\n",
    "#         super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "#         self.height, self.width = input_size\n",
    "#         self.input_dim = input_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "#         self.bias = bias\n",
    "\n",
    "\n",
    "#         self.conv = keras.Sequential([\n",
    "#             layers.ZeroPadding2D(padding=self.padding),\n",
    "#             layers.Conv2D( #in_channels=self.input_dim + self.hidden_dim,\n",
    "#                               filters=4 * self.hidden_dim,\n",
    "#                               kernel_size=self.kernel_size,\n",
    "#                               padding=\"SAME\",\n",
    "#                               use_bias=self.bias)\n",
    "#         ])\n",
    "\n",
    "#     def __call__(self, input_tensor, cur_state):\n",
    "#         h_cur, c_cur = cur_state\n",
    "\n",
    "#         combined = layers.concatenate([input_tensor, h_cur], axis=3)  # concatenate along channel axis\n",
    "\n",
    "#         combined_conv = self.conv(combined)\n",
    "#         for_split_list = []\n",
    "        \n",
    "#         for i in range(combined_conv.shape[3] // self.hidden_dim):\n",
    "#             for_split_list.append(self.hidden_dim)\n",
    "#         cc_i, cc_f, cc_o, cc_g = tf.split(combined_conv, for_split_list, axis=3) # split \n",
    "#         i = tf.sigmoid(cc_i)\n",
    "#         f = tf.sigmoid(cc_f)\n",
    "#         o = tf.sigmoid(cc_o)\n",
    "#         g = tf.tanh(cc_g)\n",
    "\n",
    "#         c_next = f * c_cur + i * g\n",
    "#         h_next = o * tf.tanh(c_next)\n",
    "\n",
    "#         return h_next, c_next\n",
    "\n",
    "#     def init_hidden(self, batch_size):\n",
    "#         return (tf.zeros([batch_size, self.height, self.width, self.hidden_dim]),\n",
    "#                 tf.zeros([batch_size, self.height, self.width, self.hidden_dim]))\n",
    "\n",
    "\n",
    "# class ConvLSTM(tf.Module):\n",
    "\n",
    "#     def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "#                  batch_first=False, bias=True, return_all_layers=False):\n",
    "#         super(ConvLSTM, self).__init__()\n",
    "\n",
    "#         self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "#         # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "#         kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "#         hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "#         if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "#             raise ValueError('Inconsistent list length.')\n",
    "\n",
    "#         self.height, self.width = input_size\n",
    "\n",
    "#         self.input_dim = input_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.batch_first = batch_first\n",
    "#         self.bias = bias\n",
    "#         self.return_all_layers = return_all_layers\n",
    "\n",
    "#         cell_list = []\n",
    "#         for i in range(0, self.num_layers):\n",
    "#             cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "#             cell_list.append(ConvLSTMCell(input_size=(self.height, self.width),\n",
    "#                                           input_dim=cur_input_dim,\n",
    "#                                           hidden_dim=self.hidden_dim[i],\n",
    "#                                           kernel_size=self.kernel_size[i],\n",
    "#                                           bias=self.bias))\n",
    "\n",
    "#         # self.cell_list = nn.ModuleList(cell_list)\n",
    "#         self.cell_list = cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_list = []\n",
    "# height, width = 128, 256\n",
    "# hidden_dim = [ 3,3,3,3,3,3,3,3,3,3,3,3]\n",
    "# kernel_size = [[3,3],[3,3],[3,3],[3,3],[3,3],[3,3],[3,3],[3,3],[3,3],[3,3],[3,3],[3,3]]\n",
    "# bias = True\n",
    "# for i in range(0, 10):\n",
    "#     cur_input_dim = 3 \n",
    "\n",
    "#     cell_list.append(ConvLSTMCell(input_size=(height, width),\n",
    "#                                     input_dim=cur_input_dim,\n",
    "#                                     hidden_dim=hidden_dim[i],\n",
    "#                                     kernel_size=kernel_size[i],\n",
    "#                                     bias=bias))\n",
    "\n",
    "# # self.cell_list = nn.ModuleList(cell_list)\n",
    "# cell_list = cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_list[0].init_hidden(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[22. 28.]\n [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# 텐서 생성\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[22. 28.]\n [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# 텐서를 CPU에 할당\n",
    "with tf.device('/CPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus[0])\n",
    "if gpus:\n",
    "  # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf929ba3211af63dc586dafc790d80eecfc9c4c3ae888cf6380685b6a965da52"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}