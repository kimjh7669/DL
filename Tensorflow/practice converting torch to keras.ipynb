{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c61dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "out_ch = 10\n",
    "in_ch = 100\n",
    "\n",
    "class double_conv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None, input_shape = [28,28, in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class inconv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class down(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = keras.Sequential(\n",
    "            layers.MaxPooling2D(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class up(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            self.up = layers.UpSampling2D(size = (2,2), interpolation='bilinear')\n",
    "        else:\n",
    "            self.up = layers.Conv2DTranspose(in_ch//2, 2, stride=(2, 2))\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x1.size()[2] - x2.size()[2]\n",
    "        diffY = x1.size()[3] - x2.size()[3]\n",
    "        x2 = F.pad(x2, (diffX // 2, int(diffX / 2),\n",
    "                        diffY // 2, int(diffY / 2)))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "model = up(in_ch, out_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1614918e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_22 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6edd672394b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdouble_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_ch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_ch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m# model.forward(model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# print(model.summary())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-6edd672394b5>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_ch, out_ch)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_ch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_ch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         self.conv = keras.Sequential([\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_ch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0min_ch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# keras에서 input_channel의 수가 중요한가?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                                 input_list)\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    860\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2682\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2683\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2684\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2685\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    235\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_22 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 100)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "out_ch = 10\n",
    "in_ch = 100\n",
    "# model = keras.Sequential([\n",
    "#     layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None, input_shape=(28,28,in_ch)), # keras에서 input_channel의 수가 중요한가?\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu'),\n",
    "#     layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')   \n",
    "# ])\n",
    "\n",
    "class double_conv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None, input_shape = [in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, 3, padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "model = double_conv(in_ch, out_ch)\n",
    "# model.forward(model)\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28e99b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] echo\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"echo\", help=\"write the string u want to echo\")\n",
    "args = parser.parse_args()\n",
    "print(args.echo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27d7d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1],\n",
      "        [2, 3]]), tensor([[4, 5],\n",
      "        [6, 7]]), tensor([[8, 9]])) 1\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = torch.arange(10).reshape(5,2)\n",
    "# print(x)\n",
    "print(torch.split(x, 2),1)\n",
    "# print(torch.split(x, [1,4]))\n",
    "\n",
    "y = np.arange(10).reshape(5,2)\n",
    "try:\n",
    "    print(tf.split(y, 2),1)\n",
    "except:\n",
    "    print(\"Hello\")\n",
    "# print(tf.split(y, [1,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ec59d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (5): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (6): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (7): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (8): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (9): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "print(nn.ModuleList(nn.Linear(10,10) for i in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87cea798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 1,270\n",
      "Trainable params: 1,230\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "out_ch = 10\n",
    "in_ch = 3\n",
    "\n",
    "model = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None, input_shape = [28,28, in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "\n",
    "# model.summary()\n",
    "cell_list = []\n",
    "for i in range(10):\n",
    "    cell_list.append(model)\n",
    "for i in range(10):\n",
    "    print(cell_list[i].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d399cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model1 =  nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "cell_list1 = []\n",
    "for i in range(10):\n",
    "    cell_list1.append(model1)\n",
    "ModuleList1 = nn.ModuleList(cell_list1)\n",
    "print(ModuleList1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92e7019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(tf.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = keras.Sequential([\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None, input_shape = [28,28, in_ch]), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(out_ch, (3, 3), padding = \"SAME\", activation=None), # keras에서 input_channel의 수가 중요한가?\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu')            \n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "model2 = double_conv(in_ch, out_ch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34c8ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv1(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv1, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "model3 = double_conv1(in_ch, out_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0de5dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.         0.5232661  0.47687265 ... 0.35606608 0.27586213\n",
      "    0.        ]\n",
      "   [0.17035584 0.22723347 0.17924874 ... 0.         0.5292986\n",
      "    0.18800136]\n",
      "   [0.         0.4469407  0.         ... 0.2808789  0.47486067\n",
      "    0.4821635 ]\n",
      "   ...\n",
      "   [0.24947824 0.32432446 0.38637814 ... 0.12459311 0.01071548\n",
      "    0.14527945]\n",
      "   [0.         0.03043439 0.         ... 0.         0.19401371\n",
      "    0.22159222]\n",
      "   [0.         0.08166632 0.08650278 ... 0.         0.14612302\n",
      "    0.21135893]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.38910618 0.         ... 0.         0.\n",
      "    0.6584822 ]\n",
      "   [0.41976556 0.17575815 0.         ... 0.         0.\n",
      "    0.03930255]\n",
      "   ...\n",
      "   [0.         0.0079676  0.         ... 0.         0.39524004\n",
      "    0.5703057 ]\n",
      "   [0.         0.03304046 0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.23874667 0.12957491 0.20419379 ... 0.15720464 0.\n",
      "    0.03838756]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.09551699 0.5359171\n",
      "    0.1336831 ]\n",
      "   [0.         0.5877851  0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.04420311 0.0147508  0.         ... 0.5152231  0.14467905\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.42326963 0.7505373  0.         ... 0.30054244 0.13674885\n",
      "    0.26261815]\n",
      "   [0.         0.13957928 0.14355129 ... 0.         0.\n",
      "    0.22445135]\n",
      "   [0.34888336 0.19876352 0.         ... 0.         0.\n",
      "    0.12758125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.64063525 0.22457114 0.04710364 ... 0.         0.42542616\n",
      "    0.42273602]\n",
      "   [0.27892902 0.         0.17958863 ... 0.         0.\n",
      "    0.91834277]\n",
      "   [0.         0.34417596 0.         ... 0.19522652 0.46436492\n",
      "    0.24281958]\n",
      "   ...\n",
      "   [0.         0.3256862  0.2606577  ... 0.         0.2304111\n",
      "    0.39774144]\n",
      "   [0.29366818 0.         0.1399409  ... 0.         0.\n",
      "    0.41855195]\n",
      "   [0.00503625 0.         0.         ... 0.         0.\n",
      "    0.26228875]]\n",
      "\n",
      "  [[0.         0.23133726 0.08128412 ... 0.         0.32934278\n",
      "    0.        ]\n",
      "   [0.         0.23151006 0.00378288 ... 0.10277531 0.21396206\n",
      "    0.1581253 ]\n",
      "   [0.08480042 0.         0.04786139 ... 0.         0.5909983\n",
      "    0.6201209 ]\n",
      "   ...\n",
      "   [0.         0.68365693 0.         ... 0.         0.49864784\n",
      "    0.4081857 ]\n",
      "   [0.58836645 0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.21130528]]\n",
      "\n",
      "  [[0.         0.09145343 0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.14687277]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.38472527 0.\n",
      "    0.        ]\n",
      "   [0.         0.05587279 0.         ... 0.         0.\n",
      "    0.8131025 ]\n",
      "   [0.24259366 0.         0.1823384  ... 0.         0.\n",
      "    0.        ]]]], shape=(1, 28, 28, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ts = np.random.randn(28*28*3).reshape(1,28, 28, 3)\n",
    "\n",
    "print(model2.conv(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf0fc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fa2854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST('data/', train = True, transform = transformation, download = True)\n",
    "test_dataset = datasets.MNIST('data/', train = False, transform = transformation, download = True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5eb3dea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-06-28T19:15:09.689718</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 248.518125 \r\n",
       "L 251.565 248.518125 \r\n",
       "L 251.565 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 244.365 224.64 \r\n",
       "L 244.365 7.2 \r\n",
       "L 26.925 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p1914debc12)\">\r\n",
       "    <image height=\"218\" id=\"image50c514276d\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAEmElEQVR4nO3dIW+TaxzG4bcnc5WDoNCjtR0OEuxkk9mhOoPhC4CCWTQg0UuqmWOr6cT0apFsyM32fIL3T+hp7/Z012XvvMmTLL88yd607TRNM2+Alfpn3QeAh0BoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGATvrPsBDNBwOy/3jx4/lvre3V+6vXr0q98lkUu4snxsNAoQGAUKDAKFBgNAgQGgQIDQI6DRNM1/3IbbR48ePW7fLy8vy2W63W+5HR0flfnV1Ve43NzflzvK50SBAaBAgNAgQGgQIDQKEBgFCgwCfR1uRDx8+tG5Pnz4tn33z5k25f//+faEzsT5uNAgQGgQIDQKEBgFCgwChQYDQIMB7tBXpdDoLbU3TNOPxeNnHYc3caBAgNAgQGgQIDQKEBgFCgwD/3l+R+bz9W/yqrWn+/LNMvi7u/8eNBgFCgwChQYDQIEBoECA0CBAaBHiPtgZ/+phMv98v98lksszjEOBGgwChQYDQIEBoECA0CBAaBAgNArxHW5HqXddoNCqfffHiRbl//fp1oTOxPm40CBAaBAgNAoQGAUKDAKFBgNAgwHu0Fbm4uGjdfv/+XT7b6/WWfRzWzI0GAUKDAKFBgNAgQGgQIDQI6DRNU/+GEEv36dOncn/79m25HxwclPvZ2dlfn4nVcqNBgNAgQGgQIDQIEBoECA0ChAYBPiazBtfX1+X+p591Gg6H5e492uZxo0GA0CBAaBAgNAgQGgQIDQKEBgE+j7YGz549K/cfP36U++7ubrnv7Hg9umncaBAgNAgQGgQIDQKEBgFCgwChQYD3aBvo8+fP5X58fFzuh4eH5T4ej//6TPw3bjQIEBoECA0ChAYBQoMAoUGA0CDAe7QNNBgMyn06nZb7bDYr9+fPn7du9/f35bMsxo0GAUKDAKFBgNAgQGgQIDQI8O/9DdTtdsv98vKy3Hu9Xrnv7++3bldXV+WzLMaNBgFCgwChQYDQIEBoECA0CBAaBPh9nw10d3dX7u/evSv309PTcn/58mXr5j3aarjRIEBoECA0CBAaBAgNAoQGAUKDAJ9H20Lzef0n/fXrV+v25MmTZR+Hxo0GEUKDAKFBgNAgQGgQIDQIEBoE+DzaFvry5Uu5j0aj1u3Ro0fls7e3twud6aFzo0GA0CBAaBAgNAgQGgQIDQKEBgHeo22h2WxW7p1Op3Xr9/vls+fn5wud6aFzo0GA0CBAaBAgNAgQGgQIDQJ83dwWGgwG5T6dTlu3yWRSPvv69ety//nzZ7k/VG40CBAaBAgNAoQGAUKDAKFBgNAgwHu0LdTtdst9OBy2bt++fSufPTk5Kff379+X+0PlRoMAoUGA0CBAaBAgNAgQGgQIDQK8R4MANxoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CDgX3DgiADr9r3IAAAAAElFTkSuQmCC\" y=\"-6.64\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"md55332ecc9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#md55332ecc9\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#md55332ecc9\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 5 -->\r\n",
       "      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#md55332ecc9\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#md55332ecc9\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 15 -->\r\n",
       "      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#md55332ecc9\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_6\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#md55332ecc9\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 25 -->\r\n",
       "      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m25554ef28f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m25554ef28f\" y=\"11.082857\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m25554ef28f\" y=\"49.911429\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 5 -->\r\n",
       "      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m25554ef28f\" y=\"88.74\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m25554ef28f\" y=\"127.568571\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 15 -->\r\n",
       "      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m25554ef28f\" y=\"166.397143\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m25554ef28f\" y=\"205.225714\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 25 -->\r\n",
       "      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 26.925 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 244.365 224.64 \r\n",
       "L 244.365 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 244.365 224.64 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 26.925 7.2 \r\n",
       "L 244.365 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p1914debc12\">\r\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-06-28T19:15:09.784740</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 248.518125 \r\n",
       "L 251.565 248.518125 \r\n",
       "L 251.565 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 244.365 224.64 \r\n",
       "L 244.365 7.2 \r\n",
       "L 26.925 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#pa3e63eb82b)\">\r\n",
       "    <image height=\"218\" id=\"image93cc10ece5\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-6.64\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"mf3b2280a14\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#mf3b2280a14\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#mf3b2280a14\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 5 -->\r\n",
       "      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#mf3b2280a14\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#mf3b2280a14\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 15 -->\r\n",
       "      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#mf3b2280a14\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_6\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#mf3b2280a14\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 25 -->\r\n",
       "      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m9de5cfc076\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9de5cfc076\" y=\"11.082857\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9de5cfc076\" y=\"49.911429\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 5 -->\r\n",
       "      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9de5cfc076\" y=\"88.74\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9de5cfc076\" y=\"127.568571\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 15 -->\r\n",
       "      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9de5cfc076\" y=\"166.397143\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9de5cfc076\" y=\"205.225714\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 25 -->\r\n",
       "      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 26.925 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 244.365 224.64 \r\n",
       "L 244.365 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 244.365 224.64 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 26.925 7.2 \r\n",
       "L 244.365 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"pa3e63eb82b\">\r\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_data = next(iter(train_loader))\n",
    "def plot_img(image):\n",
    "    image = image.numpy()[0]\n",
    "    mean = 0.1307\n",
    "    std = 0.3081\n",
    "    image = ((std * image) + mean) \n",
    "    plt.imshow(image, cmap = 'gray') \n",
    "    plt.show()\n",
    "plot_img(sample_data[0][2])\n",
    "plot_img(sample_data[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26243403",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a3340009ab74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\ntarget:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d(p = 0.1)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1) \n",
    "model = Net()\n",
    "# if is_cuda:\n",
    "#     model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "data, target = next(iter(train_loader))\n",
    "output = model(Variable(data.cuda()))\n",
    "print('output:', output.size(), \"\\ntarget:\", target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f35b1e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]], shape=(3, 4), dtype=int32)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32) tf.Tensor([4 5 6 7], shape=(4,), dtype=int32) tf.Tensor([ 8  9 10 11], shape=(4,), dtype=int32)\n",
      "tensor([0, 1, 2, 3]) tensor([4, 5, 6, 7]) tensor([ 8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "x = tf.reshape(tf.range(12), (3,4))\n",
    "print(x)\n",
    "p, q, r = tf.unstack(x)\n",
    "p.shape.as_list()\n",
    "print(p,q,r)\n",
    "\n",
    "y = torch.reshape(torch.tensor(range(12)), (3,4))\n",
    "\n",
    "a,b,c = torch.unbind(y)\n",
    "print(a,b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4009c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import operator\n",
    "\n",
    "vgg16_bn = models.vgg16_bn(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999295ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 1 GPU limited 256.0MB memory\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_vgg16 = tf.keras.applications.VGG16(\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce53691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vgg16_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3088f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tf_vgg16.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(9)\n",
    "x = x.reshape(1,1,3,3)\n",
    "y = tf_vgg16(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "863ad388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 1, 2],\n",
       "         [3, 4, 5],\n",
       "         [6, 7, 8]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad3c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf929ba3211af63dc586dafc790d80eecfc9c4c3ae888cf6380685b6a965da52"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}